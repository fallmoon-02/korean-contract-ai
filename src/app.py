import os
import json
import torch
import faiss
import openai
from flask import Flask, request, jsonify, render_template
from transformers import BertTokenizer, BertForSequenceClassification

app = Flask(__name__, static_folder="static", template_folder="templates")

# 1. ëª¨ë¸ ë¡œë“œ (Hugging Face)
MODEL_ID = "5wqs/kobert-risk-final"
HF_TOKEN = os.getenv("HF_TOKEN")

tokenizer = BertTokenizer.from_pretrained(MODEL_ID, token=HF_TOKEN)
model = BertForSequenceClassification.from_pretrained(MODEL_ID, token=HF_TOKEN)
model.eval()

# 2. Faiss ì¸ë±ìŠ¤ ë° í…œí”Œë¦¿ ID ë¡œë“œ
INDEX_PATH = os.path.join("templates_index", "templates.faiss")
IDS_PATH = os.path.join("templates_index", "templates_ids.json")

faiss_index = faiss.read_index(INDEX_PATH)
with open(IDS_PATH, "r", encoding="utf-8") as f:
    template_ids = json.load(f)

# 3. OpenAI í‚¤
openai.api_key = os.getenv("OPENAI_API_KEY")

# ------------------------- ë¼ìš°íŠ¸ -------------------------

# ğŸ”¹ í™ˆ í™”ë©´
@app.route("/", methods=["GET"])
def home():
    return render_template("index.html")


# ğŸ”¹ ê³„ì•½ì„œ ì´ˆì•ˆ ìƒì„±
@app.route("/generate_draft", methods=["POST"])
def generate_draft():
    data = request.get_json()
    a = data.get("party_a", "")
    b = data.get("party_b", "")
    purpose = data.get("subject", "")
    date = data.get("date", "")

    prompt = f"""
ë‹¹ì‚¬ì A: {a}
ë‹¹ì‚¬ì B: {b}
ê³„ì•½ ëª©ì : {purpose}
íš¨ë ¥ ë°œìƒì¼: {date}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œêµ­ì–´ ìš©ì—­ ê³„ì•½ì„œ ì´ˆì•ˆì„ ì¡°í•­ë³„ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”. ê° ì¡°í•­ì€ ë²ˆí˜¸ì™€ ì œëª©ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
"""

    try:
        res = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=1500
        )
        draft = res.choices[0].message.content.strip()
        return jsonify({"draft": draft})

    except Exception as e:
        return jsonify({"error": str(e)}), 500


# ğŸ”¹ ë¦¬ìŠ¤í¬ ë¶„ì„
@app.route("/analyze_risk", methods=["POST"])
def analyze_risk():
    data = request.get_json()
    clause = data.get("clause")
    if not clause:
        return jsonify({"error": "clause is required"}), 400

    inputs = tokenizer(clause, return_tensors="pt", truncation=True, padding="max_length", max_length=256)
    with torch.no_grad():
        logits = model(**inputs).logits
    pred = torch.argmax(logits, dim=1).item()
    label = "HighRisk" if pred == 1 else "LowRisk"

    return jsonify({"label": label})


# ğŸ”¹ ìœ ì‚¬ í…œí”Œë¦¿ ì¶”ì²œ
@app.route("/recommend_templates", methods=["POST"])
def recommend_templates():
    data = request.get_json()
    clause = data.get("clause", "")
    topk = int(data.get("topk", 3))

    inputs = tokenizer(clause, return_tensors="pt", truncation=True, padding="max_length", max_length=256)
    with torch.no_grad():
        vec = model.bert(**inputs).last_hidden_state.mean(dim=1).cpu().numpy().astype("float32")
    faiss.normalize_L2(vec)

    D, I = faiss_index.search(vec, topk)
    results = []
    for i, idx in enumerate(I[0]):
        template = template_ids[idx]
        results.append({
            "template_id": template.get("id", f"T{idx+1}"),
            "title": template.get("title", "ì œëª© ì—†ìŒ"),
            "snippet": template.get("text", "")[:100],
            "score": float(D[0][i])
        })

    return jsonify({"templates": results})


# ğŸ”¹ ì•± ì‹¤í–‰
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
